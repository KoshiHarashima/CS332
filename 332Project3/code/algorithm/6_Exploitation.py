# 6_Exploitation.py
# Exploitative algorithm: waits and exploits when opponent bids below value
# Strategy:
# 1. Initially doesn't bid (or bids very low)
# 2. Observes opponent's bids from losses
# 3. When opponent bids below our value, we bid optimally (slightly above opponent)
import numpy as np
from typing import List, Tuple

def exploitation_algorithm(player_id: int, value: float, round_num: int,
                          history: List[Tuple[float, float, bool]],
                          env_state: dict) -> float:
    """
    Exploitative algorithm: waits and exploits when opponent bids low
    
    Strategy:
    - Initially doesn't participate in bidding (bids very low)
    - Observes opponent's bids from losses
    - When opponent's bid is confirmed to be below our value, 
      we bid optimally (slightly above opponent to win with positive utility)
    
    Args:
        player_id: player ID (0 or 1)
        value: player's value (v)
        round_num: current round number
        history: list of (bid, utility, won) tuples for this player
        env_state: dict with additional info
    
    Returns:
        bid: selected bid
    """
    # Initial observation phase: don't bid (bid very low)
    observation_rounds = env_state.get('observation_rounds', 20)
    
    # Discretize: select from k discrete arms
    k = env_state.get('k', 100)
    bid_grid = np.linspace(0, value, k)
    
    if round_num < observation_rounds:
        # Observation phase: bid very low to observe opponent
        target_bid = value * 0.01  # Very low bid to observe without winning
        discrete_bid_idx = np.argmin(np.abs(bid_grid - target_bid))
        return bid_grid[discrete_bid_idx]
    
    # After observation phase, analyze opponent's bids
    if len(history) == 0:
        target_bid = value * 0.01
        discrete_bid_idx = np.argmin(np.abs(bid_grid - target_bid))
        return bid_grid[discrete_bid_idx]
    
    # Store previous estimated opponent bid for tracking changes
    if 'prev_estimated_opponent_bid' not in env_state:
        env_state['prev_estimated_opponent_bid'] = value  # Initialize to high value
    
    # Estimate opponent's bid from history
    # When we lose: opponent_bid >= our_bid (we know opponent bid >= our last bid)
    # When we win: opponent_bid < our_bid (exact value unknown, but < our bid)
    
    # Collect observed opponent bid lower bounds from losses
    opponent_bid_lower_bounds = []
    for bid, utility, won in history:
        if not won:  # We lost, so opponent_bid >= our_bid
            opponent_bid_lower_bounds.append(bid)
    
    if len(opponent_bid_lower_bounds) == 0:
        # Never lost, so we don't have good estimate of opponent's bid
        # Continue observing
        target_bid = value * 0.01
        discrete_bid_idx = np.argmin(np.abs(bid_grid - target_bid))
        return bid_grid[discrete_bid_idx]
    
    # Estimate opponent's recent bid
    # Use maximum of recent lower bounds as estimate
    recent_rounds = min(10, len(opponent_bid_lower_bounds))
    recent_lower_bounds = opponent_bid_lower_bounds[-recent_rounds:]
    estimated_opponent_bid = np.mean(recent_lower_bounds)
    
    # Also consider trend: if opponent is bidding lower over time
    if len(opponent_bid_lower_bounds) >= 2:
        recent_avg = np.mean(opponent_bid_lower_bounds[-5:])
        older_avg = np.mean(opponent_bid_lower_bounds[-10:-5]) if len(opponent_bid_lower_bounds) >= 10 else recent_avg
        if recent_avg < older_avg:
            # Opponent is bidding lower, use more recent estimate
            estimated_opponent_bid = recent_avg
    
    # Check if opponent bid increased (went up)
    prev_estimated = env_state['prev_estimated_opponent_bid']
    if estimated_opponent_bid > prev_estimated:
        # Opponent bid increased - reset to observation mode (bid 0)
        env_state['prev_estimated_opponent_bid'] = estimated_opponent_bid
        target_bid = value * 0.01  # Return to observation mode
        discrete_bid_idx = np.argmin(np.abs(bid_grid - target_bid))
        return bid_grid[discrete_bid_idx]
    
    # Update previous estimate
    env_state['prev_estimated_opponent_bid'] = estimated_opponent_bid
    
    # Check if opponent bid is below our value
    # We know from losses that opponent_bid >= our_losing_bid
    # If our losing bids were all < value, then opponent_bid might be < value
    # But we need to be more careful: we want to confirm opponent_bid < value
    
    # Strategy: if estimated opponent bid is below our value, exploit
    # Optimal bid: slightly above opponent to win, with positive utility
    if estimated_opponent_bid < value:
        # Opponent is bidding below our value - exploit!
        # Bid slightly above opponent to win
        # Ensure value - bid > 0 (positive utility)
        optimal_bid = min(estimated_opponent_bid * 1.01, value * 0.99)
        
        # Make sure we have positive utility: value - bid > 0
        optimal_bid = min(optimal_bid, value * 0.95)  # Safety margin
        
        # Discretize the optimal bid
        discrete_bid_idx = np.argmin(np.abs(bid_grid - optimal_bid))
        return bid_grid[discrete_bid_idx]
    else:
        # Opponent bid might be >= value, or we don't have good estimate
        # Continue observing with low bid
        target_bid = value * 0.01
        discrete_bid_idx = np.argmin(np.abs(bid_grid - target_bid))
        return bid_grid[discrete_bid_idx]

