{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2480fd",
   "metadata": {},
   "source": [
    "- As project 2, I made functions at .py file, and then ,plot results in .ipynb file. \n",
    "- I condider Repeated First Price Auction(hereinafter called repeated FPA), not second price auction.\n",
    "- Players in Repeated FPA must have algorithm whose regret coverges to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d25f97",
   "metadata": {},
   "source": [
    "# Project 3: Repeated First Price Auction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918afd6",
   "metadata": {},
   "source": [
    "## Information Setting\n",
    "\n",
    "- Full Information: Each player knows their own value (v) which is fixed across all rounds\n",
    "- Full Feedback: After each round, each player observes all bids from all players, not just their own outcome\n",
    "\n",
    "This setting allows players to use opponent's bid history directly in their learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ff7a9",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "- n_rounds: 1000 - number of rounds per simulation\n",
    "- k: 100 - number of discrete arms (discretization level)\n",
    "- n_mc: 100 - number of Monte Carlo simulation runs\n",
    "- h: scaling parameter (default: value) - used in Exponential Weight algorithms\n",
    "- value (v): 10.0 - player's value for the item (default)\n",
    "- learning_rate: sqrt(log(k) / n) - learning rate for Exponential Weight algorithms (default for flexible)\n",
    "  Optimal learning rate: epsilon = sqrt(log(k) / T)\n",
    "  Note: cumulative_payoffs are normalized by h, so epsilon does not need h factor\n",
    "- observation_rounds: 5 - number of observation rounds for exploitation algorithm (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a26536",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "\n",
    "1. 1_empirical: Empirical algorithm - always maximizes current round expected utility based on past opponent's bid data. \n",
    "2. 2_ew: Flexible algorithm - Exponential Weight with learning_rate\n",
    "3. 3_Exploitation: Exploitation algorithm - waits and exploits when opponent bids low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e0c2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path('algorithm').resolve()))\n",
    "\n",
    "empirical, ew, exploitation = [importlib.import_module(m) for m in ['1_empirical', '2_ew', '3_exploitation']]\n",
    "\n",
    "import repeated_FPA\n",
    "from repeated_FPA import run_repeated_fpa, plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2db87",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "- we simulate the game with players who use above algorithms (This is Part1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7c7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_rounds = 10000\n",
    "k = 100\n",
    "n_mc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e642af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC iteration 10/10 completed\n",
      "Completed: Empirical vs EW\n",
      "Plot 1 saved to: ../figures/empirical_vs_ew_bid_evolution.png\n",
      "Plot 2 saved to: ../figures/empirical_vs_ew_regret.png\n",
      "Plot 4 saved to: ../figures/empirical_vs_ew_utility_distribution.png\n",
      "Plot 5 saved to: ../figures/empirical_vs_ew_win_rate_distribution.png\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Player 1:\n",
      "  Mean Regret: 3.70 ± 1.21\n",
      "  Mean Utility: 346.00 ± 21.20\n",
      "  Mean Win Rate: 0.513 ± 0.011\n",
      "\n",
      "Player 2:\n",
      "  Mean Regret: 84.32 ± 5.10\n",
      "  Mean Utility: 285.56 ± 28.83\n",
      "  Mean Win Rate: 0.487 ± 0.011\n",
      "Summary statistics saved to: ../data/empirical_vs_ew_summary.csv\n",
      "Detailed results saved to: ../data/empirical_vs_ew_detailed.csv\n",
      "Regret history saved to: ../data/empirical_vs_ew_regret_history.csv\n",
      "Bid history saved to: ../data/empirical_vs_ew_bid_history.csv\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Empirical vs EW\n",
    "# Note: ew_algorithm uses optimal learning_rate = sqrt(log(k) / n) by default\n",
    "# Optimal learning rate: epsilon = sqrt(log(k) / T)\n",
    "\n",
    "v1, v2 = 1.0, 1.0\n",
    "player1 = (empirical.empirical_algorithm, v1, {'k': k, 'h': v1})\n",
    "player2 = (ew.flexible_algorithm, v2, {'k': k, 'h': v2, 'learning_rate': None})  # None = default (sqrt(log(k) / n)), or specify a value like 0.1\n",
    "results_empirical_vs_ew = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: Empirical vs EW\")\n",
    "plot_results(results_empirical_vs_ew, title=\"Empirical vs EW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06c2abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harashimakoshi/CS332/332Project3/code/algorithm/2_ew.py:110: RuntimeWarning: overflow encountered in power\n",
      "  powers = (1 + learning_rate) ** (cumulative_payoffs / h)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC iteration 10/10 completed\n",
      "Completed: FTL vs EW\n",
      "Plot 1 saved to: ../figures/ftl_vs_ew_bid_evolution.png\n",
      "Plot 2 saved to: ../figures/ftl_vs_ew_regret.png\n",
      "Plot 4 saved to: ../figures/ftl_vs_ew_utility_distribution.png\n",
      "Plot 5 saved to: ../figures/ftl_vs_ew_win_rate_distribution.png\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Player 1:\n",
      "  Mean Regret: 1428.12 ± 70.39\n",
      "  Mean Utility: 985.70 ± 50.44\n",
      "  Mean Win Rate: 0.483 ± 0.004\n",
      "\n",
      "Player 2:\n",
      "  Mean Regret: 31.82 ± 9.86\n",
      "  Mean Utility: 1755.43 ± 81.80\n",
      "  Mean Win Rate: 0.517 ± 0.004\n",
      "Summary statistics saved to: ../data/ftl_vs_ew_summary.csv\n",
      "Detailed results saved to: ../data/ftl_vs_ew_detailed.csv\n",
      "Regret history saved to: ../data/ftl_vs_ew_regret_history.csv\n",
      "Bid history saved to: ../data/ftl_vs_ew_bid_history.csv\n"
     ]
    }
   ],
   "source": [
    "v1, v2 = 1.0, 1.0\n",
    "player1 = (ew.flexible_algorithm, v1, {'k': k, 'h': v1, 'learning_rate': 100})\n",
    "player2 = (ew.flexible_algorithm, v2, {'k': k, 'h': v2, 'learning_rate': None})\n",
    "results_FTL_vs_ew = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: FTL vs EW\")\n",
    "plot_results(results_FTL_vs_ew, title=\"FTL vs EW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2f0907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC iteration 10/10 completed\n",
      "Completed: Uniform guessing vs EW\n",
      "Plot 1 saved to: ../figures/uniform_guessing_vs_ew_bid_evolution.png\n",
      "Plot 2 saved to: ../figures/uniform_guessing_vs_ew_regret.png\n",
      "Plot 4 saved to: ../figures/uniform_guessing_vs_ew_utility_distribution.png\n",
      "Plot 5 saved to: ../figures/uniform_guessing_vs_ew_win_rate_distribution.png\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Player 1:\n",
      "  Mean Regret: 324.31 ± 6.51\n",
      "  Mean Utility: 804.58 ± 13.32\n",
      "  Mean Win Rate: 0.485 ± 0.002\n",
      "\n",
      "Player 2:\n",
      "  Mean Regret: 87.56 ± 6.09\n",
      "  Mean Utility: 978.65 ± 20.52\n",
      "  Mean Win Rate: 0.515 ± 0.002\n",
      "Summary statistics saved to: ../data/uniform_guessing_vs_ew_summary.csv\n",
      "Detailed results saved to: ../data/uniform_guessing_vs_ew_detailed.csv\n",
      "Regret history saved to: ../data/uniform_guessing_vs_ew_regret_history.csv\n",
      "Bid history saved to: ../data/uniform_guessing_vs_ew_bid_history.csv\n"
     ]
    }
   ],
   "source": [
    "v1, v2 = 1.0, 1.0\n",
    "player1 = (ew.flexible_algorithm, v1, {'k': k, 'h': v1, 'learning_rate': 0.01})\n",
    "player2 = (ew.flexible_algorithm, v2, {'k': k, 'h': v2, 'learning_rate': None})\n",
    "results_uniform_vs_ew = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: Uniform guessing vs EW\")\n",
    "plot_results(results_uniform_vs_ew, title=\"Uniform guessing vs EW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d716f713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC iteration 10/10 completed\n",
      "Completed: Optimal LR vs 3x Optimal LR\n",
      "Plot 1 saved to: ../figures/optimal_lr_vs_3x_optimal_lr_bid_evolution.png\n",
      "Plot 2 saved to: ../figures/optimal_lr_vs_3x_optimal_lr_regret.png\n",
      "Plot 4 saved to: ../figures/optimal_lr_vs_3x_optimal_lr_utility_distribution.png\n",
      "Plot 5 saved to: ../figures/optimal_lr_vs_3x_optimal_lr_win_rate_distribution.png\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Player 1:\n",
      "  Mean Regret: 77.08 ± 6.83\n",
      "  Mean Utility: 528.00 ± 12.30\n",
      "  Mean Win Rate: 0.506 ± 0.004\n",
      "\n",
      "Player 2:\n",
      "  Mean Regret: 66.87 ± 5.07\n",
      "  Mean Utility: 521.09 ± 14.62\n",
      "  Mean Win Rate: 0.494 ± 0.004\n",
      "Summary statistics saved to: ../data/optimal_lr_vs_3x_optimal_lr_summary.csv\n",
      "Detailed results saved to: ../data/optimal_lr_vs_3x_optimal_lr_detailed.csv\n",
      "Regret history saved to: ../data/optimal_lr_vs_3x_optimal_lr_regret_history.csv\n",
      "Bid history saved to: ../data/optimal_lr_vs_3x_optimal_lr_bid_history.csv\n"
     ]
    }
   ],
   "source": [
    "# Optimal learning rate vs 3x optimal learning rate\n",
    "# Optimal learning rate: epsilon = sqrt(log(k) / n_rounds)\n",
    "import numpy as np\n",
    "\n",
    "v1, v2 = 1.0, 1.0\n",
    "optimal_lr = np.sqrt(np.log(k) / n_rounds)\n",
    "lr_3x = 3 * optimal_lr\n",
    "\n",
    "player1 = (ew.flexible_algorithm, v1, {'k': k, 'h': v1, 'learning_rate': None})\n",
    "player2 = (ew.flexible_algorithm, v2, {'k': k, 'h': v2, 'learning_rate': lr_3x})\n",
    "\n",
    "results_lr_comparison = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: Optimal LR vs 3x Optimal LR\")\n",
    "plot_results(results_lr_comparison, title=\"Optimal LR vs 3x Optimal LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524f344",
   "metadata": {},
   "source": [
    "# Part 1 - 2\n",
    "what if they have different value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33dadc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC iteration 10/10 completed\n",
      "Completed: EW vs EW\n",
      "Plot 1 saved to: ../figures/ew_vs_ew_with_different_values_bid_evolution.png\n",
      "Plot 2 saved to: ../figures/ew_vs_ew_with_different_values_regret.png\n",
      "Plot 4 saved to: ../figures/ew_vs_ew_with_different_values_utility_distribution.png\n",
      "Plot 5 saved to: ../figures/ew_vs_ew_with_different_values_win_rate_distribution.png\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Player 1:\n",
      "  Mean Regret: 63.91 ± 3.94\n",
      "  Mean Utility: 5908.73 ± 5.38\n",
      "  Mean Win Rate: 0.991 ± 0.001\n",
      "\n",
      "Player 2:\n",
      "  Mean Regret: 5.32 ± 0.93\n",
      "  Mean Utility: 0.82 ± 0.22\n",
      "  Mean Win Rate: 0.009 ± 0.001\n",
      "Summary statistics saved to: ../data/ew_vs_ew_with_different_values_summary.csv\n",
      "Detailed results saved to: ../data/ew_vs_ew_with_different_values_detailed.csv\n",
      "Regret history saved to: ../data/ew_vs_ew_with_different_values_regret_history.csv\n",
      "Bid history saved to: ../data/ew_vs_ew_with_different_values_bid_history.csv\n"
     ]
    }
   ],
   "source": [
    "v1, v2 = 0.9, 0.3\n",
    "player1 = (ew.flexible_algorithm, v1, {'k': k, 'h': v1, 'learning_rate': None})\n",
    "player2 = (ew.flexible_algorithm, v2, {'k': k, 'h': v2, 'learning_rate': None}) \n",
    "results_ew_vs_ew_with_different_values = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: EW vs EW\")\n",
    "plot_results(results_ew_vs_ew_with_different_values, title=\"EW vs EW (with different values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bda409",
   "metadata": {},
   "source": [
    "# Part 1 - 3\n",
    "what if values are drawn from distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f89ffbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from value_generate import generate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b869b131",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'function' and 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m player1 = (ew.flexible_algorithm, \u001b[38;5;28;01mlambda\u001b[39;00m: generate_value(\u001b[33m'\u001b[39m\u001b[33muniform\u001b[39m\u001b[33m'\u001b[39m, low=\u001b[32m0.0\u001b[39m, high=\u001b[32m1.0\u001b[39m), {\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m: k, \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}) \n\u001b[32m      9\u001b[39m player2 = (ew.flexible_algorithm, \u001b[38;5;28;01mlambda\u001b[39;00m: generate_value(\u001b[33m'\u001b[39m\u001b[33muniform\u001b[39m\u001b[33m'\u001b[39m, low=\u001b[32m0.0\u001b[39m, high=\u001b[32m1.0\u001b[39m), {\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m: k, \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}) \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m results_ew_vs_ew_from_uniform_distribution = \u001b[43mrun_repeated_fpa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCompleted: EW vs EW from uniform distribution\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m plot_results(results_ew_vs_ew_from_uniform_distribution, title=\u001b[33m\"\u001b[39m\u001b[33mEW vs EW from uniform distribution\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CS332/332Project3/code/repeated_FPA.py:93\u001b[39m, in \u001b[36mrun_repeated_fpa\u001b[39m\u001b[34m(player1_config, player2_config, n_rounds, n_mc, k)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Reset for each MC run\u001b[39;00m\n\u001b[32m     92\u001b[39m history1 = []\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m history2 = []\n\u001b[32m     94\u001b[39m env1_state = env1.copy()\n\u001b[32m     95\u001b[39m env2_state = env2.copy()\n",
      "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'function' and 'function'"
     ]
    }
   ],
   "source": [
    "# Parameters for uniform distribution experiment\n",
    "n_rounds = 10000\n",
    "k = 100\n",
    "n_mc = 10\n",
    "\n",
    "# Use lambda functions to generate values for each MC run\n",
    "# Each MC run will get a new value from uniform distribution\n",
    "player1 = (ew.flexible_algorithm, lambda: generate_value('uniform', low=0.0, high=1.0), {'k': k, 'learning_rate': None}) \n",
    "player2 = (ew.flexible_algorithm, lambda: generate_value('uniform', low=0.0, high=1.0), {'k': k, 'learning_rate': None}) \n",
    "results_ew_vs_ew_from_uniform_distribution = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: EW vs EW from uniform distribution\")\n",
    "plot_results(results_ew_vs_ew_from_uniform_distribution, title=\"EW vs EW from uniform distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf81acd",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "- Exploitation strategy vs 1_empirical (Empirical strategy)\n",
    "- Exploitation strategy vs 2_ew (Exponential Weight algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f82a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Implementation\n",
    "\n",
    "# Parameters\n",
    "n_rounds = 10000\n",
    "k = 10\n",
    "n_mc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af66f1e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m player1 = (ew.flexible_algorithm, v1, {\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m: k, \u001b[33m'\u001b[39m\u001b[33mh\u001b[39m\u001b[33m'\u001b[39m: v1, \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m})  \n\u001b[32m      3\u001b[39m player2 = (exploitation.exploitation_algorithm, v2, {\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m: k, \u001b[33m'\u001b[39m\u001b[33mh\u001b[39m\u001b[33m'\u001b[39m: v2, \u001b[33m'\u001b[39m\u001b[33mobservation_rounds\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5\u001b[39m})\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m results_ew_vs_exploitation = \u001b[43mrun_repeated_fpa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCompleted: EW vs Exploitation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plot_results(results_ew_vs_exploitation, title=\u001b[33m\"\u001b[39m\u001b[33mEW vs Exploitation\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CS332/332Project3/code/repeated_FPA.py:103\u001b[39m, in \u001b[36mrun_repeated_fpa\u001b[39m\u001b[34m(player1_config, player2_config, n_rounds, n_mc, k)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m round_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_rounds):\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# Get bids from each player\u001b[39;00m\n\u001b[32m    102\u001b[39m     bid1 = alg1_func(\u001b[32m0\u001b[39m, v1, round_num, history1, env1_state)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     bid2 = \u001b[43malg2_func\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv2_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     bids1_history.append(bid1)\n\u001b[32m    106\u001b[39m     bids2_history.append(bid2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CS332/332Project3/code/algorithm/3_exploitation.py:109\u001b[39m, in \u001b[36mexploitation_algorithm\u001b[39m\u001b[34m(player_id, value, round_num, history, env_state)\u001b[39m\n\u001b[32m    101\u001b[39m exploitation_threshold = value * threshold_ratio\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predicted_opponent_bid < exploitation_threshold:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# Exploit: maximize expected utility on bid grid\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# Use empirical distribution from observed opponent bids to calculate P(win)\u001b[39;00m\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# and find bid that maximizes (value - bid) * P(win|bid)\u001b[39;00m\n\u001b[32m    107\u001b[39m     \n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Calculate win probabilities for each bid in grid (with tie handling)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     win_probs = \u001b[43mcalculate_win_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopponent_bids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbid_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Expected utility = (value - bid) * P(win|bid)\u001b[39;00m\n\u001b[32m    112\u001b[39m     expected_utility = (value - bid_grid) * win_probs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CS332/332Project3/code/algorithm/3_exploitation.py:165\u001b[39m, in \u001b[36mcalculate_win_probability\u001b[39m\u001b[34m(observed_bids, bid_grid)\u001b[39m\n\u001b[32m    163\u001b[39m count_less = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ob \u001b[38;5;129;01min\u001b[39;00m observed_bids \u001b[38;5;28;01mif\u001b[39;00m ob < bid)\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Use np.isclose with appropriate tolerance for tie detection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m count_equal = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_bids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[43matol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# P(win|bid) = P(opponent_bid < bid) + 0.5 * P(opponent_bid == bid)\u001b[39;00m\n\u001b[32m    168\u001b[39m p_less = count_less / n_obs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CS332/332Project3/code/algorithm/3_exploitation.py:165\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    163\u001b[39m count_less = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ob \u001b[38;5;129;01min\u001b[39;00m observed_bids \u001b[38;5;28;01mif\u001b[39;00m ob < bid)\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Use np.isclose with appropriate tolerance for tie detection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m count_equal = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ob \u001b[38;5;129;01min\u001b[39;00m observed_bids \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[43matol\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# P(win|bid) = P(opponent_bid < bid) + 0.5 * P(opponent_bid == bid)\u001b[39;00m\n\u001b[32m    168\u001b[39m p_less = count_less / n_obs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/_core/numeric.py:2483\u001b[39m, in \u001b[36misclose\u001b[39m\u001b[34m(a, b, rtol, atol, equal_nan)\u001b[39m\n\u001b[32m   2480\u001b[39m     y = \u001b[38;5;28mfloat\u001b[39m(y)\n\u001b[32m   2482\u001b[39m \u001b[38;5;66;03m# atol and rtol can be arrays\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2483\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np.all(np.isfinite(atol)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m   2484\u001b[39m     err_s = np.geterr()[\u001b[33m\"\u001b[39m\u001b[33minvalid\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2485\u001b[39m     err_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOne of rtol or atol is not valid, atol: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00matol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, rtol: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrtol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2675\u001b[39m, in \u001b[36mall\u001b[39m\u001b[34m(a, axis, out, keepdims, where)\u001b[39m\n\u001b[32m   2589\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[32m   2590\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mall\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, *, where=np._NoValue):\n\u001b[32m   2591\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2592\u001b[39m \u001b[33;03m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[32m   2593\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2673\u001b[39m \n\u001b[32m   2674\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2675\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction_any_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_and\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:100\u001b[39m, in \u001b[36m_wrapreduction_any_all\u001b[39m\u001b[34m(obj, ufunc, method, axis, out, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc.reduce(obj, axis, \u001b[38;5;28mbool\u001b[39m, out, **passkwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/_core/_methods.py:72\u001b[39m, in \u001b[36m_all\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where=where)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "v1, v2 = 0.9, 0.3\n",
    "player1 = (ew.flexible_algorithm, v1, {'k': k, 'h': v1, 'learning_rate': None})  \n",
    "player2 = (exploitation.exploitation_algorithm, v2, {'k': k, 'h': v2, 'observation_rounds': 5})\n",
    "results_ew_vs_exploitation = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: EW vs Exploitation\")\n",
    "plot_results(results_ew_vs_exploitation, title=\"EW vs Exploitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3acc841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_rounds = 1000\n",
    "k = 10\n",
    "n_mc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8325db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: EW vs Exploitation\n",
      "Plot 1 saved to: ../figures/ew_vs_exploitation_for_detail_bid_evolution.png\n",
      "Plot 2 saved to: ../figures/ew_vs_exploitation_for_detail_regret.png\n",
      "Plot 4 saved to: ../figures/ew_vs_exploitation_for_detail_utility_distribution.png\n",
      "Plot 5 saved to: ../figures/ew_vs_exploitation_for_detail_win_rate_distribution.png\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Player 1:\n",
      "  Mean Regret: 14.60 ± 0.00\n",
      "  Mean Utility: 632.55 ± 0.00\n",
      "  Mean Win Rate: 0.882 ± 0.000\n",
      "\n",
      "Player 2:\n",
      "  Mean Regret: 51.18 ± 0.00\n",
      "  Mean Utility: 13.32 ± 0.00\n",
      "  Mean Win Rate: 0.118 ± 0.000\n",
      "Summary statistics saved to: ../data/ew_vs_exploitation_for_detail_summary.csv\n",
      "Detailed results saved to: ../data/ew_vs_exploitation_for_detail_detailed.csv\n",
      "Regret history saved to: ../data/ew_vs_exploitation_for_detail_regret_history.csv\n",
      "Bid history saved to: ../data/ew_vs_exploitation_for_detail_bid_history.csv\n"
     ]
    }
   ],
   "source": [
    "v1, v2 = 0.9, 0.3\n",
    "# Use default learning rate (sqrt(log(k) / n)) - no need to specify explicitly\n",
    "player1 = (ew.flexible_algorithm, v1, {'k': k, 'h': v1, 'learning_rate': None})  \n",
    "player2 = (exploitation.exploitation_algorithm, v2, {'k': k, 'h': v2, 'observation_rounds': 5})\n",
    "results_ew_vs_exploitation_for_detail = run_repeated_fpa(player1, player2, n_rounds, n_mc, k=k)\n",
    "print(\"Completed: EW vs Exploitation\")\n",
    "plot_results(results_ew_vs_exploitation_for_detail, title=\"EW vs Exploitation (for detail)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
