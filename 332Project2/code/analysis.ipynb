{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8be4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create figures directory if it doesn't exist\n",
    "os.makedirs('../../figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f49872",
   "metadata": {},
   "source": [
    "- what to do\n",
    "    - give raphs for each learning rate\n",
    "    - the change of regret?, total payoff, decisions?\n",
    "    - horizontal axis must be the number of rounds\n",
    "    - vertical axis must be one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066662b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions (k): 10\n",
      "Number of rounds (n): 1000\n",
      "Random epsilon: 0.001000\n",
      "Theoretical optimal epsilon: 0.047985\n",
      "FTL epsilon: 1000\n"
     ]
    }
   ],
   "source": [
    "# Define variables and learning rates\n",
    "k = 10  # actions\n",
    "n = 1000  #  rounds\n",
    "\n",
    "# Three important learning rates to compare:\n",
    "# 1. Random \n",
    "epsilon_random = 0.001  \n",
    "\n",
    "# 2. Theoretical optimal\n",
    "epsilon_optimal = np.sqrt(np.log(k) / n)\n",
    "\n",
    "# 3. FTL\n",
    "epsilon_ftl = 1000  \n",
    "\n",
    "print(f\"Number of actions (k): {k}\")\n",
    "print(f\"Number of rounds (n): {n}\")\n",
    "print(f\"Random epsilon: {epsilon_random:.6f}\")\n",
    "print(f\"Theoretical optimal epsilon: {epsilon_optimal:.6f}\")\n",
    "print(f\"FTL epsilon: {epsilon_ftl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6538b8e",
   "metadata": {},
   "source": [
    "- plot\n",
    "    - regret for each round\n",
    "    - total payoff for each round\n",
    "    - action chosen for each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aeec014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Exponential Weights Algorithm\n",
    "class ExponentialWeights:\n",
    "    # Three Parameters:\n",
    "    \n",
    "    def __init__(self, k, epsilon, n):\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        self.n = n\n",
    "        self.weights = np.ones(k)  # Initialize weights to 1\n",
    "        self.cumulative_payoffs = np.zeros(k)  # Track cumulative payoffs\n",
    "        self.regret_history = []  # Track regret over time\n",
    "        self.total_payoff = 0  # Track total payoff\n",
    "        self.action_history = []  # Track actions taken\n",
    "        \n",
    "    def select_action(self):\n",
    "        \"\"\"Select action based on current weights\"\"\"\n",
    "        if self.epsilon == 0 or np.all(self.weights == 0):\n",
    "            # Random selection when epsilon is 0\n",
    "            action = np.random.randint(0, self.k)\n",
    "        else:\n",
    "            # Normalize weights to get probabilities\n",
    "            probabilities = self.weights / np.sum(self.weights)\n",
    "            action = np.random.choice(self.k, p=probabilities)\n",
    "        \n",
    "        self.action_history.append(action)\n",
    "        return action\n",
    "    \n",
    "    def update_weights(self, payoffs):\n",
    "        \"\"\"\n",
    "        Update weights based on received payoffs\n",
    "        \n",
    "        Parameters:\n",
    "        - payoffs: array of payoffs for each action in this round\n",
    "        \"\"\"\n",
    "        # Update cumulative payoffs\n",
    "        self.cumulative_payoffs += payoffs\n",
    "        \n",
    "        # Update total payoff (payoff of selected action)\n",
    "        selected_action = self.action_history[-1]\n",
    "        self.total_payoff += payoffs[selected_action]\n",
    "        \n",
    "        # Update weights: w_i = w_i * exp(epsilon * payoff_i)\n",
    "        if self.epsilon > 0:\n",
    "            self.weights *= np.exp(self.epsilon * payoffs)\n",
    "        \n",
    "        # Calculate regret: max cumulative payoff - our cumulative payoff\n",
    "        max_cumulative = np.max(self.cumulative_payoffs)\n",
    "        our_cumulative = self.cumulative_payoffs[selected_action]\n",
    "        regret = max_cumulative - our_cumulative\n",
    "        self.regret_history.append(regret)\n",
    "    \n",
    "    def run_algorithm(self, payoff_generator):\n",
    "        \"\"\"\n",
    "        Run the algorithm for n rounds\n",
    "        \n",
    "        Parameters:\n",
    "        - payoff_generator: function that generates payoffs for each round\n",
    "        \"\"\"\n",
    "        for round_num in range(self.n):\n",
    "            # Select action\n",
    "            action = self.select_action()\n",
    "            \n",
    "            # Generate payoffs for this round\n",
    "            payoffs = payoff_generator(round_num)\n",
    "            \n",
    "            # Update weights\n",
    "            self.update_weights(payoffs)\n",
    "        \n",
    "        return {\n",
    "            'regret_history': self.regret_history,\n",
    "            'total_payoff': self.total_payoff,\n",
    "            'action_history': self.action_history,\n",
    "            'cumulative_payoffs': self.cumulative_payoffs\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fdb29",
   "metadata": {},
   "source": [
    "# A. Adversarial Fair Payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bea05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Adversarial Fair Payoffs Model...\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Create payoff generator\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m adversarial_generator = AdversarialFairPayoffs(\u001b[43mk\u001b[49m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Test with different learning rates\u001b[39;00m\n\u001b[32m     44\u001b[39m ew_random_adv = ExponentialWeights(k, epsilon_random, n)\n",
      "\u001b[31mNameError\u001b[39m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "# A. Adversarial Fair Payoffs Implementation\n",
    "class AdversarialFairPayoffs:\n",
    "    \"\"\"\n",
    "    Adversarial Fair Payoffs model:\n",
    "    - In each round, draw a payoff x ~ U[0,1]\n",
    "    - Assign this payoff to the action with smallest total payoff so far\n",
    "    - All other actions get 0 payoff\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.cumulative_payoffs = np.zeros(k)\n",
    "    \n",
    "    def generate_payoffs(self, round_num):\n",
    "        \"\"\"\n",
    "        Generate payoffs for a given round\n",
    "        \n",
    "        Returns:\n",
    "        - payoffs: array of payoffs for each action\n",
    "        \"\"\"\n",
    "        # Draw a random payoff from uniform distribution [0,1]\n",
    "        payoff = np.random.uniform(0, 1)\n",
    "        \n",
    "        # Find the action with smallest cumulative payoff\n",
    "        min_action = np.argmin(self.cumulative_payoffs)\n",
    "        \n",
    "        # Create payoff vector: only the min action gets the payoff, others get 0\n",
    "        payoffs = np.zeros(self.k)\n",
    "        payoffs[min_action] = payoff\n",
    "        \n",
    "        # Update cumulative payoffs\n",
    "        self.cumulative_payoffs += payoffs\n",
    "        \n",
    "        return payoffs\n",
    "\n",
    "# Test Adversarial Fair Payoffs\n",
    "print(\"Testing Adversarial Fair Payoffs Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create payoff generator\n",
    "adversarial_generator = AdversarialFairPayoffs(k)\n",
    "\n",
    "# Test with different learning rates\n",
    "ew_random_adv = ExponentialWeights(k, epsilon_random, n)\n",
    "ew_optimal_adv = ExponentialWeights(k, epsilon_optimal, n)\n",
    "ew_ftl_adv = ExponentialWeights(k, epsilon_ftl, n)\n",
    "\n",
    "# Run algorithms\n",
    "results_random_adv = ew_random_adv.run_algorithm(adversarial_generator.generate_payoffs)\n",
    "results_optimal_adv = ew_optimal_adv.run_algorithm(adversarial_generator.generate_payoffs)\n",
    "results_ftl_adv = ew_ftl_adv.run_algorithm(adversarial_generator.generate_payoffs)\n",
    "\n",
    "# Create results dictionary for adversarial payoffs\n",
    "results_dict_adv = {\n",
    "    f'Random (ε={epsilon_random:.6f})': results_random_adv,\n",
    "    f'Optimal (ε={epsilon_optimal:.6f})': results_optimal_adv,\n",
    "    f'FTL (ε={epsilon_ftl})': results_ftl_adv\n",
    "}\n",
    "\n",
    "# Plot comparison for adversarial payoffs\n",
    "plot_learning_rate_comparison(results_dict_adv, \"Exponential Weights: Learning Rate Comparison (Adversarial Fair Payoffs)\")\n",
    "\n",
    "# Print summary statistics for adversarial payoffs\n",
    "print(\"\\nAdversarial Fair Payoffs - Summary Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "for name, results in results_dict_adv.items():\n",
    "    final_regret = results['regret_history'][-1]\n",
    "    total_payoff = results['total_payoff']\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Final Regret: {final_regret:.4f}\")\n",
    "    print(f\"  Total Payoff: {total_payoff:.4f}\")\n",
    "    print(f\"  Best Action: Action {np.argmax(results['cumulative_payoffs'])}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3889ad",
   "metadata": {},
   "source": [
    "# B. Bernoulli Payoffs Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4709cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Bernoulli Payoffs Model...\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Create payoff generator\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m bernoulli_generator = BernoulliPayoffs(\u001b[43mk\u001b[49m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Test with different learning rates\u001b[39;00m\n\u001b[32m     33\u001b[39m ew_random_bern = ExponentialWeights(k, epsilon_random, n)\n",
      "\u001b[31mNameError\u001b[39m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "class BernoulliPayoffs:\n",
    "    \"\"\"\n",
    "    Bernoulli Payoffs model:\n",
    "    - Fix a probability p_j for each action j with p_j in [0, 1/2]\n",
    "    - In each round, draw payoff for each action j as v_j ~ B(p_j)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        # Generate probabilities for each action (all in [0, 1/2])\n",
    "        self.probabilities = np.random.uniform(0, 0.5, k)\n",
    "        print(f\"Bernoulli probabilities for each action: {self.probabilities}\")\n",
    "    \n",
    "    def generate_payoffs(self, round_num):\n",
    "        \"\"\"\n",
    "        Generate payoffs for a given round\n",
    "        \n",
    "        Returns:\n",
    "        - payoffs: array of payoffs for each action (0 or 1)\n",
    "        \"\"\"\n",
    "        # Generate Bernoulli payoffs for each action\n",
    "        payoffs = np.random.binomial(1, self.probabilities)\n",
    "        return payoffs\n",
    "\n",
    "# Test Bernoulli Payoffs\n",
    "print(\"\\nTesting Bernoulli Payoffs Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create payoff generator\n",
    "bernoulli_generator = BernoulliPayoffs(k)\n",
    "\n",
    "# Test with different learning rates\n",
    "ew_random_bern = ExponentialWeights(k, epsilon_random, n)\n",
    "ew_optimal_bern = ExponentialWeights(k, epsilon_optimal, n)\n",
    "ew_ftl_bern = ExponentialWeights(k, epsilon_ftl, n)\n",
    "\n",
    "# Run algorithms\n",
    "results_random_bern = ew_random_bern.run_algorithm(bernoulli_generator.generate_payoffs)\n",
    "results_optimal_bern = ew_optimal_bern.run_algorithm(bernoulli_generator.generate_payoffs)\n",
    "results_ftl_bern = ew_ftl_bern.run_algorithm(bernoulli_generator.generate_payoffs)\n",
    "\n",
    "# Create results dictionary for Bernoulli payoffs\n",
    "results_dict_bern = {\n",
    "    f'Random (ε={epsilon_random:.6f})': results_random_bern,\n",
    "    f'Optimal (ε={epsilon_optimal:.6f})': results_optimal_bern,\n",
    "    f'FTL (ε={epsilon_ftl})': results_ftl_bern\n",
    "}\n",
    "\n",
    "# Plot comparison for Bernoulli payoffs\n",
    "plot_learning_rate_comparison(results_dict_bern, \"Exponential Weights: Learning Rate Comparison (Bernoulli Payoffs)\")\n",
    "\n",
    "# Print summary statistics for Bernoulli payoffs\n",
    "print(\"\\nBernoulli Payoffs - Summary Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "for name, results in results_dict_bern.items():\n",
    "    final_regret = results['regret_history'][-1]\n",
    "    total_payoff = results['total_payoff']\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Final Regret: {final_regret:.4f}\")\n",
    "    print(f\"  Total Payoff: {total_payoff:.4f}\")\n",
    "    print(f\"  Best Action: Action {np.argmax(results['cumulative_payoffs'])}\")\n",
    "    print()\n",
    "\n",
    "# Show the true probabilities for reference\n",
    "print(\"True Bernoulli probabilities for each action:\")\n",
    "for i, prob in enumerate(bernoulli_generator.probabilities):\n",
    "    print(f\"  Action {i}: {prob:.4f}\")\n",
    "print(f\"Best action (highest probability): Action {np.argmax(bernoulli_generator.probabilities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ba2b4",
   "metadata": {},
   "source": [
    "# Data in the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず, ノーマルとRUSHのどちらかのコンディションが状態移遷する.\n",
    "\n",
    "# 以下が, それぞれについてデータによって決められている. i.i.d.である\n",
    "# normal_hit_prob_per_spinは, ノーマルコンディションでの1回転当たりの勝ち確率.\n",
    "# rush_hit_prob_per_spinは, RUSHコンディションでの1回転当たりの勝ち確率.\n",
    "# rush_every_prov_given_hitは, ノーマルコンディションで当たりが出た後に, RUSHコンディションに移行する確率.\n",
    "# rush_continue_probは, RUSHコンディションで当たりが出た後に, 次の当たりが出るまで継続する確率.\n",
    "# rush_st_spinsは, RUSHコンディションで当たりが出た後に, 次の当たりが出るまでのスピン数.\n",
    "# payouts_normal_balls は, ノーマルコンディションでの当たりの賞金.\n",
    "# payouts_rush_balls は, RUSHコンディションでの当たりの賞金.\n",
    "\n",
    "#　グラフを作成する.　一流誌に載せるようなグラフ(状態遷移とpayoffのグラフ)\n",
    "\n",
    "# ここからExponential Weights Algorithmを適用する."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa39dde",
   "metadata": {},
   "source": [
    "# Adversarial generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed57338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pachinko Data Overview:\n",
      "==================================================\n",
      "Number of machines: 5\n",
      "\n",
      "Data columns:\n",
      "  - machine\n",
      "  - maker\n",
      "  - normal_hit_prob_per_spin\n",
      "  - rush_hit_prob_per_spin\n",
      "  - rush_entry_prob_given_hit\n",
      "  - rush_continuation_prob\n",
      "  - rush_st_spins\n",
      "  - payouts_normal_balls\n",
      "  - payouts_rush_balls\n",
      "  - source_urls\n",
      "\n",
      "First few rows:\n",
      "                                 machine        maker  \\\n",
      "0                 e Tokyo Ghoul W (スマパチ)        Bisty   \n",
      "1  PF Gundam Unicorn Reappearance 129ver       SANKYO   \n",
      "2                 P Madoka Magica 3 (LT)      KYORAKU   \n",
      "3                e 新世紀エヴァンゲリオン 〜はじまりの記憶〜        Bisty   \n",
      "4              e Re:ゼロから始める異世界生活 season2  DAITO GIKEN   \n",
      "\n",
      "   normal_hit_prob_per_spin  rush_hit_prob_per_spin  \\\n",
      "0                  0.002501                0.010493   \n",
      "1                  0.007704                0.024631   \n",
      "2                  0.005003                0.016077   \n",
      "3                  0.003333                0.010000   \n",
      "4                  0.003125                0.009900   \n",
      "\n",
      "   rush_entry_prob_given_hit  rush_continuation_prob  rush_st_spins  \\\n",
      "0                       0.51                    0.75            130   \n",
      "1                       0.51                    0.80             60   \n",
      "2                       0.55                    0.65             60   \n",
      "3                       0.60                    0.81            100   \n",
      "4                       0.55                    0.77            100   \n",
      "\n",
      "  payouts_normal_balls payouts_rush_balls  \\\n",
      "0             300,1500          3000,6000   \n",
      "1              300,700            300,700   \n",
      "2             400,1500           400,1500   \n",
      "3             450,1500          1500,3000   \n",
      "4             450,1500     1500,3000,6000   \n",
      "\n",
      "                                         source_urls  \n",
      "0   https://www.p-world.co.jp/machine/database/10249  \n",
      "1  https://www.sankyo-fever.jp/products/machine_l...  \n",
      "2  https://1geki.jp/pachinko/p_madokamagica3/; ht...  \n",
      "3  https://www.p-world.co.jp/machine/database/104...  \n",
      "4  https://p-town.dmm.com/machines/4448; https://...  \n",
      "\n",
      "Machine Names:\n",
      "  0: e Tokyo Ghoul W (スマパチ)\n",
      "  1: PF Gundam Unicorn Reappearance 129ver\n",
      "  2: P Madoka Magica 3 (LT)\n",
      "  3: e 新世紀エヴァンゲリオン 〜はじまりの記憶〜\n",
      "  4: e Re:ゼロから始める異世界生活 season2\n"
     ]
    }
   ],
   "source": [
    "# Load Pachinko data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Pachinko data\n",
    "pachinko_data = pd.read_csv('/Users/harashimakoshi/CS332/332Project2/data/data_pachinko.csv')\n",
    "\n",
    "print(\"Pachinko Data Overview:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of machines: {len(pachinko_data)}\")\n",
    "print(\"\\nData columns:\")\n",
    "for col in pachinko_data.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(pachinko_data.head())\n",
    "\n",
    "# Display machine names\n",
    "print(\"\\nMachine Names:\")\n",
    "for i, machine in enumerate(pachinko_data['machine']):\n",
    "    print(f\"  {i}: {machine}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0bf9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512b205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pachinko Machine Payoff Generator\n",
    "class PachinkoPayoffGenerator:\n",
    "    \"\"\"\n",
    "    Pachinko machine payoff generator based on normal/rush state transitions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, machine_data, n_rounds=1000):\n",
    "        self.machine_data = machine_data\n",
    "        self.n_rounds = n_rounds\n",
    "        \n",
    "        # Extract parameters from machine data\n",
    "        self.normal_hit_prob = machine_data['normal_hit_prob_per_spin']\n",
    "        self.rush_hit_prob = machine_data['rush_hit_prob_per_spin']\n",
    "        self.rush_entry_prob = machine_data['rush_entry_prob_given_hit']\n",
    "        self.rush_continue_prob = machine_data['rush_continuation_prob']\n",
    "        self.rush_st_spins = machine_data['rush_st_spins']\n",
    "        \n",
    "        # Parse payouts (assuming they are comma-separated strings)\n",
    "        self.payouts_normal = [int(x) for x in machine_data['payouts_normal_balls'].split(',')]\n",
    "        self.payouts_rush = [int(x) for x in machine_data['payouts_rush_balls'].split(',')]\n",
    "        \n",
    "        # Initialize state\n",
    "        self.current_state = 'normal'  # 'normal' or 'rush'\n",
    "        self.rush_spins_remaining = 0\n",
    "        \n",
    "        print(f\"Machine: {machine_data['machine']}\")\n",
    "        print(f\"Normal hit prob: {self.normal_hit_prob:.6f}\")\n",
    "        print(f\"Rush hit prob: {self.rush_hit_prob:.6f}\")\n",
    "        print(f\"Rush entry prob: {self.rush_entry_prob:.4f}\")\n",
    "        print(f\"Rush continue prob: {self.rush_continue_prob:.4f}\")\n",
    "        print(f\"Rush ST spins: {self.rush_st_spins}\")\n",
    "        print(f\"Normal payouts: {self.payouts_normal}\")\n",
    "        print(f\"Rush payouts: {self.payouts_rush}\")\n",
    "    \n",
    "    def generate_payoffs(self, round_num):\n",
    "        \"\"\"\n",
    "        Generate payoffs for a given round based on current state\n",
    "        \"\"\"\n",
    "        payoffs = np.zeros(2)  # [normal_action, rush_action]\n",
    "        \n",
    "        if self.current_state == 'normal':\n",
    "            # Normal state: can choose to play or not\n",
    "            if np.random.random() < self.normal_hit_prob:\n",
    "                # Hit in normal state\n",
    "                payoff = np.random.choice(self.payouts_normal)\n",
    "                payoffs[0] = payoff  # Normal action gets payoff\n",
    "                \n",
    "                # Check if we enter rush state\n",
    "                if np.random.random() < self.rush_entry_prob:\n",
    "                    self.current_state = 'rush'\n",
    "                    self.rush_spins_remaining = self.rush_st_spins\n",
    "                    print(f\"Round {round_num}: Entered RUSH state! Spins remaining: {self.rush_spins_remaining}\")\n",
    "            else:\n",
    "                # No hit in normal state\n",
    "                payoffs[0] = 0\n",
    "                \n",
    "        elif self.current_state == 'rush':\n",
    "            # Rush state: guaranteed hits with higher probability\n",
    "            if self.rush_spins_remaining > 0:\n",
    "                if np.random.random() < self.rush_hit_prob:\n",
    "                    # Hit in rush state\n",
    "                    payoff = np.random.choice(self.payouts_rush)\n",
    "                    payoffs[1] = payoff  # Rush action gets payoff\n",
    "                    \n",
    "                    # Check if rush continues\n",
    "                    if np.random.random() < self.rush_continue_prob:\n",
    "                        self.rush_spins_remaining -= 1\n",
    "                    else:\n",
    "                        self.current_state = 'normal'\n",
    "                        self.rush_spins_remaining = 0\n",
    "                        print(f\"Round {round_num}: Exited RUSH state\")\n",
    "                else:\n",
    "                    # No hit in rush state\n",
    "                    payoffs[1] = 0\n",
    "                    self.rush_spins_remaining -= 1\n",
    "            else:\n",
    "                # Rush state ended\n",
    "                self.current_state = 'normal'\n",
    "                payoffs[1] = 0\n",
    "        \n",
    "        return payoffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc03c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Exponential Weights Algorithm for Pachinko\n",
    "class PachinkoExponentialWeights:\n",
    "    \"\"\"\n",
    "    Exponential Weights Algorithm adapted for Pachinko machines\n",
    "    with 2 actions: Normal play vs Rush play\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon, n_rounds=1000):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_rounds = n_rounds\n",
    "        self.k = 2  # Two actions: normal and rush\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = np.ones(self.k)\n",
    "        self.cumulative_payoffs = np.zeros(self.k)\n",
    "        self.regret_history = []\n",
    "        self.total_payoff = 0\n",
    "        self.action_history = []\n",
    "        self.state_history = []  # Track state transitions\n",
    "        self.payoff_history = []  # Track payoffs over time\n",
    "        \n",
    "    def select_action(self):\n",
    "        \"\"\"Select action based on current weights\"\"\"\n",
    "        if self.epsilon == 0 or np.all(self.weights == 0):\n",
    "            action = np.random.randint(0, self.k)\n",
    "        else:\n",
    "            probabilities = self.weights / np.sum(self.weights)\n",
    "            action = np.random.choice(self.k, p=probabilities)\n",
    "        \n",
    "        self.action_history.append(action)\n",
    "        return action\n",
    "    \n",
    "    def update_weights(self, payoffs, current_state):\n",
    "        \"\"\"Update weights based on received payoffs\"\"\"\n",
    "        # Update cumulative payoffs\n",
    "        self.cumulative_payoffs += payoffs\n",
    "        \n",
    "        # Update total payoff (payoff of selected action)\n",
    "        selected_action = self.action_history[-1]\n",
    "        self.total_payoff += payoffs[selected_action]\n",
    "        \n",
    "        # Update weights: w_i = w_i * exp(epsilon * payoff_i)\n",
    "        if self.epsilon > 0:\n",
    "            self.weights *= np.exp(self.epsilon * payoffs)\n",
    "        \n",
    "        # Calculate regret: max cumulative payoff - our cumulative payoff\n",
    "        max_cumulative = np.max(self.cumulative_payoffs)\n",
    "        our_cumulative = self.cumulative_payoffs[selected_action]\n",
    "        regret = max_cumulative - our_cumulative\n",
    "        self.regret_history.append(regret)\n",
    "        \n",
    "        # Store state and payoff info\n",
    "        self.state_history.append(current_state)\n",
    "        self.payoff_history.append(payoffs.copy())\n",
    "    \n",
    "    def run_algorithm(self, payoff_generator):\n",
    "        \"\"\"Run the algorithm for n rounds\"\"\"\n",
    "        for round_num in range(self.n_rounds):\n",
    "            # Select action\n",
    "            action = self.select_action()\n",
    "            \n",
    "            # Generate payoffs for this round\n",
    "            payoffs = payoff_generator(round_num)\n",
    "            \n",
    "            # Get current state from generator\n",
    "            current_state = payoff_generator.current_state\n",
    "            \n",
    "            # Update weights\n",
    "            self.update_weights(payoffs, current_state)\n",
    "        \n",
    "        return {\n",
    "            'regret_history': self.regret_history,\n",
    "            'total_payoff': self.total_payoff,\n",
    "            'action_history': self.action_history,\n",
    "            'cumulative_payoffs': self.cumulative_payoffs,\n",
    "            'state_history': self.state_history,\n",
    "            'payoff_history': self.payoff_history\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60bdcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization functions for Pachinko analysis\n",
    "def plot_pachinko_results(results, machine_name, epsilon):\n",
    "    \"\"\"Create comprehensive visualizations for Pachinko EW results\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'Exponential Weights Algorithm - {machine_name} (ε={epsilon:.6f})', fontsize=16)\n",
    "    \n",
    "    # 1. Regret over time\n",
    "    axes[0, 0].plot(results['regret_history'], linewidth=2)\n",
    "    axes[0, 0].set_title('Regret Over Time')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Cumulative Regret')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Total payoff over time\n",
    "    cumulative_payoff = np.cumsum([results['payoff_history'][i][results['action_history'][i]] \n",
    "                                  for i in range(len(results['action_history']))])\n",
    "    axes[0, 1].plot(cumulative_payoff, linewidth=2, color='green')\n",
    "    axes[0, 1].set_title('Total Payoff Over Time')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Cumulative Payoff')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Action selection over time\n",
    "    action_colors = ['blue', 'red']\n",
    "    action_names = ['Normal', 'Rush']\n",
    "    for i in range(2):\n",
    "        action_rounds = [j for j, action in enumerate(results['action_history']) if action == i]\n",
    "        if action_rounds:\n",
    "            axes[0, 2].scatter(action_rounds, [i] * len(action_rounds), \n",
    "                             c=action_colors[i], alpha=0.6, s=1, label=action_names[i])\n",
    "    axes[0, 2].set_title('Action Selection Over Time')\n",
    "    axes[0, 2].set_xlabel('Round')\n",
    "    axes[0, 2].set_ylabel('Action')\n",
    "    axes[0, 2].set_yticks([0, 1])\n",
    "    axes[0, 2].set_yticklabels(['Normal', 'Rush'])\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. State transitions\n",
    "    state_colors = {'normal': 'lightblue', 'rush': 'orange'}\n",
    "    for i, state in enumerate(results['state_history']):\n",
    "        axes[1, 0].scatter(i, 0, c=state_colors[state], alpha=0.7, s=10)\n",
    "    axes[1, 0].set_title('State Transitions Over Time')\n",
    "    axes[1, 0].set_xlabel('Round')\n",
    "    axes[1, 0].set_ylabel('State')\n",
    "    axes[1, 0].set_yticks([])\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Payoff distribution by action\n",
    "    normal_payoffs = [results['payoff_history'][i][0] for i in range(len(results['payoff_history']))]\n",
    "    rush_payoffs = [results['payoff_history'][i][1] for i in range(len(results['payoff_history']))]\n",
    "    \n",
    "    axes[1, 1].hist(normal_payoffs, bins=20, alpha=0.7, label='Normal', color='blue')\n",
    "    axes[1, 1].hist(rush_payoffs, bins=20, alpha=0.7, label='Rush', color='red')\n",
    "    axes[1, 1].set_title('Payoff Distribution by Action')\n",
    "    axes[1, 1].set_xlabel('Payoff')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Cumulative payoffs by action\n",
    "    normal_cumulative = np.cumsum(normal_payoffs)\n",
    "    rush_cumulative = np.cumsum(rush_payoffs)\n",
    "    \n",
    "    axes[1, 2].plot(normal_cumulative, label='Normal', color='blue', linewidth=2)\n",
    "    axes[1, 2].plot(rush_cumulative, label='Rush', color='red', linewidth=2)\n",
    "    axes[1, 2].set_title('Cumulative Payoffs by Action')\n",
    "    axes[1, 2].set_xlabel('Round')\n",
    "    axes[1, 2].set_ylabel('Cumulative Payoff')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../../figures/pachinko_ew_{machine_name.replace(\" \", \"_\")}_eps{epsilon:.6f}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_machine_comparison(results_dict, title):\n",
    "    \"\"\"Compare results across different machines\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(results_dict)))\n",
    "    \n",
    "    # Regret comparison\n",
    "    for i, (name, results) in enumerate(results_dict.items()):\n",
    "        axes[0, 0].plot(results['regret_history'], label=name, color=colors[i], linewidth=2)\n",
    "    axes[0, 0].set_title('Regret Comparison')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Cumulative Regret')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Total payoff comparison\n",
    "    for i, (name, results) in enumerate(results_dict.items()):\n",
    "        cumulative_payoff = np.cumsum([results['payoff_history'][j][results['action_history'][j]] \n",
    "                                     for j in range(len(results['action_history']))])\n",
    "        axes[0, 1].plot(cumulative_payoff, label=name, color=colors[i], linewidth=2)\n",
    "    axes[0, 1].set_title('Total Payoff Comparison')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Cumulative Payoff')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final regret comparison\n",
    "    final_regrets = [results['regret_history'][-1] for results in results_dict.values()]\n",
    "    machine_names = list(results_dict.keys())\n",
    "    axes[1, 0].bar(machine_names, final_regrets, color=colors)\n",
    "    axes[1, 0].set_title('Final Regret by Machine')\n",
    "    axes[1, 0].set_ylabel('Final Regret')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final total payoff comparison\n",
    "    final_payoffs = [results['total_payoff'] for results in results_dict.values()]\n",
    "    axes[1, 1].bar(machine_names, final_payoffs, color=colors)\n",
    "    axes[1, 1].set_title('Final Total Payoff by Machine')\n",
    "    axes[1, 1].set_ylabel('Total Payoff')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../../figures/pachinko_machine_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc1cf3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Exponential Weights Algorithm on Pachinko Machines\n",
      "============================================================\n",
      "\n",
      "Testing Machine 1: e Tokyo Ghoul W (スマパチ)\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing with ε = 0.001\n",
      "Machine: e Tokyo Ghoul W (スマパチ)\n",
      "Normal hit prob: 0.002501\n",
      "Rush hit prob: 0.010493\n",
      "Rush entry prob: 0.5100\n",
      "Rush continue prob: 0.7500\n",
      "Rush ST spins: 130\n",
      "Normal payouts: [300, 1500]\n",
      "Rush payouts: [3000, 6000]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'current_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Create and run EW algorithm\u001b[39;00m\n\u001b[32m     30\u001b[39m ew_algorithm = PachinkoExponentialWeights(epsilon, n_rounds)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m results = \u001b[43mew_algorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayoff_gen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_payoffs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m     34\u001b[39m machine_results[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mε=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mPachinkoExponentialWeights.run_algorithm\u001b[39m\u001b[34m(self, payoff_generator)\u001b[39m\n\u001b[32m     63\u001b[39m payoffs = payoff_generator(round_num)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Get current state from generator\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m current_state = \u001b[43mpayoff_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_state\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.update_weights(payoffs, current_state)\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'current_state'"
     ]
    }
   ],
   "source": [
    "# Run EW Algorithm on Pachinko Machines\n",
    "print(\"Running Exponential Weights Algorithm on Pachinko Machines\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parameters\n",
    "n_rounds = 1000\n",
    "epsilon_values = [0.001, 0.01, 0.1]  # Different learning rates to test\n",
    "\n",
    "# Store results for all machines\n",
    "all_results = {}\n",
    "\n",
    "# Test on each machine\n",
    "for machine_idx in range(len(pachinko_data)):\n",
    "    machine_data = pachinko_data.iloc[machine_idx]\n",
    "    machine_name = machine_data['machine']\n",
    "    \n",
    "    print(f\"\\nTesting Machine {machine_idx + 1}: {machine_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Test different learning rates for this machine\n",
    "    machine_results = {}\n",
    "    \n",
    "    for epsilon in epsilon_values:\n",
    "        print(f\"\\nTesting with ε = {epsilon:.3f}\")\n",
    "        \n",
    "        # Create payoff generator for this machine\n",
    "        payoff_gen = PachinkoPayoffGenerator(machine_data, n_rounds)\n",
    "        \n",
    "        # Create and run EW algorithm\n",
    "        ew_algorithm = PachinkoExponentialWeights(epsilon, n_rounds)\n",
    "        results = ew_algorithm.run_algorithm(payoff_gen.generate_payoffs)\n",
    "        \n",
    "        # Store results\n",
    "        machine_results[f'ε={epsilon:.3f}'] = results\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"  Final Regret: {results['regret_history'][-1]:.4f}\")\n",
    "        print(f\"  Total Payoff: {results['total_payoff']:.4f}\")\n",
    "        print(f\"  Normal Action Payoff: {results['cumulative_payoffs'][0]:.4f}\")\n",
    "        print(f\"  Rush Action Payoff: {results['cumulative_payoffs'][1]:.4f}\")\n",
    "        print(f\"  Best Action: {'Normal' if results['cumulative_payoffs'][0] > results['cumulative_payoffs'][1] else 'Rush'}\")\n",
    "        \n",
    "        # Count state transitions\n",
    "        normal_states = sum(1 for state in results['state_history'] if state == 'normal')\n",
    "        rush_states = sum(1 for state in results['state_history'] if state == 'rush')\n",
    "        print(f\"  Normal States: {normal_states}, Rush States: {rush_states}\")\n",
    "    \n",
    "    # Store machine results\n",
    "    all_results[machine_name] = machine_results\n",
    "    \n",
    "    # Plot results for this machine (using optimal epsilon)\n",
    "    optimal_epsilon = 0.01  # Use middle value for visualization\n",
    "    if f'ε={optimal_epsilon:.3f}' in machine_results:\n",
    "        plot_pachinko_results(machine_results[f'ε={optimal_epsilon:.3f}'], \n",
    "                             machine_name, optimal_epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d04875f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARATIVE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Comparing machines with ε = 0.001\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m         epsilon_results[machine_name] = machine_results[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mε=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Plot comparison\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mplot_machine_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMachine Comparison (ε = \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepsilon\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.3f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Print summary statistics\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSummary for ε = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mplot_machine_comparison\u001b[39m\u001b[34m(results_dict, title)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_machine_comparison\u001b[39m(results_dict, title):\n\u001b[32m     80\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compare results across different machines\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     fig, axes = \u001b[43mplt\u001b[49m.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m     82\u001b[39m     fig.suptitle(title, fontsize=\u001b[32m16\u001b[39m)\n\u001b[32m     84\u001b[39m     colors = plt.cm.Set1(np.linspace(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(results_dict)))\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare results across machines and learning rates\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison plots for each learning rate\n",
    "for epsilon in epsilon_values:\n",
    "    print(f\"\\nComparing machines with ε = {epsilon:.3f}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect results for this epsilon across all machines\n",
    "    epsilon_results = {}\n",
    "    for machine_name, machine_results in all_results.items():\n",
    "        if f'ε={epsilon:.3f}' in machine_results:\n",
    "            epsilon_results[machine_name] = machine_results[f'ε={epsilon:.3f}']\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_machine_comparison(epsilon_results, f'Machine Comparison (ε = {epsilon:.3f})')\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary for ε = {epsilon:.3f}:\")\n",
    "    for machine_name, results in epsilon_results.items():\n",
    "        final_regret = results['regret_history'][-1]\n",
    "        total_payoff = results['total_payoff']\n",
    "        best_action = 'Normal' if results['cumulative_payoffs'][0] > results['cumulative_payoffs'][1] else 'Rush'\n",
    "        print(f\"  {machine_name}: Regret={final_regret:.2f}, Payoff={total_payoff:.2f}, Best={best_action}\")\n",
    "\n",
    "# Create summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for machine_name, machine_results in all_results.items():\n",
    "    for epsilon_str, results in machine_results.items():\n",
    "        epsilon_val = float(epsilon_str.split('=')[1])\n",
    "        summary_data.append({\n",
    "            'Machine': machine_name,\n",
    "            'Epsilon': epsilon_val,\n",
    "            'Final_Regret': results['regret_history'][-1],\n",
    "            'Total_Payoff': results['total_payoff'],\n",
    "            'Normal_Payoff': results['cumulative_payoffs'][0],\n",
    "            'Rush_Payoff': results['cumulative_payoffs'][1],\n",
    "            'Best_Action': 'Normal' if results['cumulative_payoffs'][0] > results['cumulative_payoffs'][1] else 'Rush'\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "summary_df.to_csv('../../data/pachinko_ew_results.csv', index=False)\n",
    "print(f\"\\nResults saved to: ../../data/pachinko_ew_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49de7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results across machines and learning rates\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison plots for each learning rate\n",
    "for epsilon in epsilon_values:\n",
    "    print(f\"\\nComparing machines with ε = {epsilon:.3f}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect results for this epsilon across all machines\n",
    "    epsilon_results = {}\n",
    "    for machine_name, machine_results in all_results.items():\n",
    "        if f'ε={epsilon:.3f}' in machine_results:\n",
    "            epsilon_results[machine_name] = machine_results[f'ε={epsilon:.3f}']\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_machine_comparison(epsilon_results, f'Machine Comparison (ε = {epsilon:.3f})')\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary for ε = {epsilon:.3f}:\")\n",
    "    for machine_name, results in epsilon_results.items():\n",
    "        final_regret = results['regret_history'][-1]\n",
    "        total_payoff = results['total_payoff']\n",
    "        best_action = 'Normal' if results['cumulative_payoffs'][0] > results['cumulative_payoffs'][1] else 'Rush'\n",
    "        print(f\"  {machine_name}: Regret={final_regret:.2f}, Payoff={total_payoff:.2f}, Best={best_action}\")\n",
    "\n",
    "# Create summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for machine_name, machine_results in all_results.items():\n",
    "    for epsilon_str, results in machine_results.items():\n",
    "        epsilon_val = float(epsilon_str.split('=')[1])\n",
    "        summary_data.append({\n",
    "            'Machine': machine_name,\n",
    "            'Epsilon': epsilon_val,\n",
    "            'Final_Regret': results['regret_history'][-1],\n",
    "            'Total_Payoff': results['total_payoff'],\n",
    "            'Normal_Payoff': results['cumulative_payoffs'][0],\n",
    "            'Rush_Payoff': results['cumulative_payoffs'][1],\n",
    "            'Best_Action': 'Normal' if results['cumulative_payoffs'][0] > results['cumulative_payoffs'][1] else 'Rush'\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "summary_df.to_csv('../../data/pachinko_ew_results.csv', index=False)\n",
    "print(f\"\\nResults saved to: ../../data/pachinko_ew_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Transition Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATE TRANSITION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def analyze_state_transitions(results, machine_name):\n",
    "    \"\"\"Analyze state transition patterns\"\"\"\n",
    "    state_history = results['state_history']\n",
    "    action_history = results['action_history']\n",
    "    \n",
    "    # Count transitions\n",
    "    normal_to_rush = 0\n",
    "    rush_to_normal = 0\n",
    "    total_transitions = 0\n",
    "    \n",
    "    for i in range(1, len(state_history)):\n",
    "        if state_history[i] != state_history[i-1]:\n",
    "            total_transitions += 1\n",
    "            if state_history[i-1] == 'normal' and state_history[i] == 'rush':\n",
    "                normal_to_rush += 1\n",
    "            elif state_history[i-1] == 'rush' and state_history[i] == 'normal':\n",
    "                rush_to_normal += 1\n",
    "    \n",
    "    # Count state durations\n",
    "    normal_durations = []\n",
    "    rush_durations = []\n",
    "    current_duration = 1\n",
    "    current_state = state_history[0]\n",
    "    \n",
    "    for i in range(1, len(state_history)):\n",
    "        if state_history[i] == current_state:\n",
    "            current_duration += 1\n",
    "        else:\n",
    "            if current_state == 'normal':\n",
    "                normal_durations.append(current_duration)\n",
    "            else:\n",
    "                rush_durations.append(current_duration)\n",
    "            current_state = state_history[i]\n",
    "            current_duration = 1\n",
    "    \n",
    "    # Add final duration\n",
    "    if current_state == 'normal':\n",
    "        normal_durations.append(current_duration)\n",
    "    else:\n",
    "        rush_durations.append(current_duration)\n",
    "    \n",
    "    print(f\"\\n{machine_name}:\")\n",
    "    print(f\"  Total transitions: {total_transitions}\")\n",
    "    print(f\"  Normal → Rush: {normal_to_rush}\")\n",
    "    print(f\"  Rush → Normal: {rush_to_normal}\")\n",
    "    print(f\"  Avg Normal duration: {np.mean(normal_durations):.2f}\")\n",
    "    print(f\"  Avg Rush duration: {np.mean(rush_durations):.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_transitions': total_transitions,\n",
    "        'normal_to_rush': normal_to_rush,\n",
    "        'rush_to_normal': rush_to_normal,\n",
    "        'avg_normal_duration': np.mean(normal_durations),\n",
    "        'avg_rush_duration': np.mean(rush_durations)\n",
    "    }\n",
    "\n",
    "# Analyze state transitions for each machine\n",
    "state_analysis = {}\n",
    "for machine_name, machine_results in all_results.items():\n",
    "    # Use middle epsilon for analysis\n",
    "    if 'ε=0.010' in machine_results:\n",
    "        state_analysis[machine_name] = analyze_state_transitions(\n",
    "            machine_results['ε=0.010'], machine_name\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6d00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
